{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv0urKZ_l08V",
    "outputId": "688b00d8-cca0-4634-eb04-f360790cc2a0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from hyperparams import hypers\n",
    "from models.yolo import Yolov2Tiny\n",
    "from models.loss import YoloLossMultiBoxes\n",
    "from train import train_fn\n",
    "from dataprocess.dataset import *\n",
    "from dataprocess.dataprocess import *\n",
    "from test import *\n",
    "from utils import *\n",
    "\n",
    "import yaml\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if hypers.DATASET_PATH == \"LOCAL\":\n",
    "    drive_dir=os.path.join(os.getcwd(), \"archive\",\"data\")\n",
    "elif hypers.DATASET_PATH == \"DRIVE\":\n",
    "    drive_dir=os.path.join(os.getcwd(),\"drive\",\"MyDrive\",\"archive\",\"data\")\n",
    "\n",
    "\n",
    "\n",
    "#Dataframe Creation\n",
    "train_labels=os.path.join(drive_dir,\"train_solution_bounding_boxes (1).csv\")\n",
    "train_imgs_dir=os.path.join(drive_dir,\"training_images\")\n",
    "test_imgs_dir=os.path.join(drive_dir,\"testing_images\")\n",
    "\n",
    "labels_dir=os.path.join(drive_dir,\"label\")\n",
    "if os.path.exists(labels_dir) == False:\n",
    "  os.mkdir(labels_dir)\n",
    "\n",
    "images_dir=os.path.join(drive_dir,\"image\")\n",
    "if os.path.exists(images_dir) == False:\n",
    "  os.mkdir(images_dir)\n",
    "\n",
    "#YOLOV8 PART START\n",
    "\n",
    "yolo_dir=os.path.join(drive_dir,\"yolov8\")\n",
    "if os.path.exists(yolo_dir) == False:\n",
    "  os.mkdir(yolo_dir)\n",
    "\n",
    "labels_dir_v8=os.path.join(yolo_dir,\"labels\")\n",
    "if os.path.exists(labels_dir_v8) == False:\n",
    "  os.mkdir(labels_dir_v8)\n",
    "\n",
    "if os.path.exists(labels_dir_v8+\"/train\") == False:\n",
    "  os.mkdir(labels_dir_v8+\"/train\")\n",
    "if os.path.exists(labels_dir_v8+\"/val\") == False:\n",
    "  os.mkdir(labels_dir_v8+\"/val2\")\n",
    "\n",
    "images_dir_v8=os.path.join(yolo_dir,\"images\")\n",
    "if os.path.exists(images_dir_v8) == False:\n",
    "  os.mkdir(images_dir_v8)\n",
    "\n",
    "if os.path.exists(images_dir_v8+\"/train\") == False:\n",
    "  os.mkdir(images_dir_v8+\"/train\")\n",
    "if os.path.exists(images_dir_v8+\"/val\") == False:\n",
    "  os.mkdir(images_dir_v8+\"/val\")\n",
    "\n",
    "prediction_dir=os.path.join(yolo_dir,\"predictions\")\n",
    "if os.path.exists(prediction_dir) == False:\n",
    "  os.mkdir(prediction_dir)\n",
    "\n",
    "\n",
    "imgs_list=list(sorted(os.listdir(train_imgs_dir)))\n",
    "idxs=list(range(len(imgs_list)))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_idx=idxs[:int(0.8*len(idxs))]\n",
    "val_idx=idxs[int(0.8*len(idxs)):]\n",
    "\n",
    "\n",
    "imgs_list=list(sorted(os.listdir(train_imgs_dir)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list(sorted(os.listdir(labels_dir)))) == 0:\n",
    "    logging.info(\"Populating v1 directories\")\n",
    "    populate_v1_dir(drive_dir, imgs_list, images_dir, labels_dir, train_imgs_dir)\n",
    "    logging.info(\"Populated v1 directories\")\n",
    "    \n",
    "if len(list(sorted(os.listdir(labels_dir_v8+\"/train\")))) == 0:\n",
    "    logging.info(\"Populating v8 directories\")\n",
    "    populate_v8_dir(drive_dir, imgs_list, images_dir_v8, labels_dir_v8, train_imgs_dir, val_idx)\n",
    "    logging.info(\"Populated v1 directories\")\n",
    "    \n",
    "yaml_path = os.path.join(yolo_dir,\"yolo.yaml\")\n",
    "if os.path.exists(yaml_path) == False:\n",
    "    generate_yolov8_yaml(yolo_dir, images_dir_v8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hypers.LOAD_MODEL_v8:\n",
    "    model = YOLO(hypers.path_best_weights_v8)\n",
    "else:\n",
    "    model=YOLO('yolov8m.pt')\n",
    "# model.train(data=yolo_dir+'/yolo.yaml',epochs=20,patience=5,batch=8,\n",
    "#                     lr0=0.0005,imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # metrics = model.val()\n",
    "# results, test_img_list = predict_yolo_v8(model, test_imgs_dir, prediction_dir)\n",
    "\n",
    "# imgs_name=['vid_5_400','vid_5_26720']\n",
    "# save_sample_pics(test_imgs_dir, imgs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov2Tiny(split_size=7, num_boxes=hypers.NUM_BOXES, num_classes=hypers.NUM_CLASSES).to(hypers.DEVICE)\n",
    "optimizer = optim.Adam( model.parameters(), lr=hypers.LEARNING_RATE, weight_decay=hypers.WEIGHT_DECAY )\n",
    "loss_fn = YoloLossMultiBoxes(S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])\n",
    "\n",
    "annotations=create_annotations(images_dir) # LIST LIKE: 0     vid_4_1000.jpg   vid_4_1000.txt\n",
    "annotations_predict=create_annotations(test_imgs_dir) # LIST LIKE: 0     vid_4_1000.jpg   vid_4_1000.txt\n",
    "\n",
    "\n",
    "dataset=VOCDataset(annotations, labels_dir, images_dir, S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, transform=transform)\n",
    "dataset_predict=VOCDatasetPredict(annotations_predict, test_imgs_dir, S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, transform=transform)\n",
    "\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [300, 55])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=hypers.BATCH_SIZE,\n",
    "                            pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=hypers.BATCH_SIZE,\n",
    "                        pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "predict_loader = DataLoader(dataset=dataset_predict, batch_size=hypers.BATCH_SIZE,\n",
    "                        pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Train mAP: 0.0\n",
      "epoch: 0 Test mAP: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.22it/s, loss=74.5]\n",
      " 10%|█         | 1/10 [00:10<01:38, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 142.1671002705892\n",
      "epoch: 1 Train mAP: 0.0\n",
      "epoch: 1 Test mAP: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.48it/s, loss=40.4]\n",
      " 20%|██        | 2/10 [00:21<01:26, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.341648737589516\n",
      "epoch: 2 Train mAP: 0.0\n",
      "epoch: 2 Test mAP: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.46it/s, loss=22.2]\n",
      " 30%|███       | 3/10 [00:32<01:15, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 30.682282235887314\n",
      "epoch: 3 Train mAP: 0.0024957258719950914\n",
      "epoch: 3 Test mAP: 0.00021404089056886733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.45it/s, loss=24.9]\n",
      " 40%|████      | 4/10 [00:43<01:04, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 22.000303586324055\n",
      "epoch: 4 Train mAP: 0.6103190779685974\n",
      "epoch: 4 Test mAP: 0.043168842792510986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:01<00:03,  3.49it/s, loss=15.8]"
     ]
    }
   ],
   "source": [
    "map_array_train = []\n",
    "map_array_test = []\n",
    "for epoch in tqdm(range(10), position=0, leave=True):\n",
    "    \n",
    "    pred_boxes, target_boxes = get_bboxes(train_loader, model, iou_threshold=0.5, threshold=0.4,S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, device=hypers.DEVICE)\n",
    "    mean_avg_prec_train = mean_average_precision(pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\")\n",
    "    \n",
    "    pred_boxes, target_boxes = get_bboxes(test_loader, model, iou_threshold=0.5, threshold=0.4,S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, device=hypers.DEVICE)\n",
    "    mean_avg_prec_test = mean_average_precision(pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\")\n",
    "    \n",
    "    map_array_train.append(mean_avg_prec_train.item())\n",
    "    map_array_train.append(mean_avg_prec_test.item())\n",
    "    \n",
    "    print(f\"epoch: {epoch} Train mAP: {mean_avg_prec_train}\")\n",
    "    print(f\"epoch: {epoch} Test mAP: {mean_avg_prec_test}\")\n",
    "    \n",
    "    # k=0\n",
    "    # if (mean_avg_prec > 0.9) and (k==0):\n",
    "    #     k=1\n",
    "    #     checkpoint = {\n",
    "    #         \"state_dict\": model.state_dict(),\n",
    "    #         \"optimizer\": optimizer.state_dict(),\n",
    "    #     }\n",
    "    #     save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE, exit_training=True)\n",
    "    #     # time.sleep(10)\n",
    "\n",
    "    train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mAP Array: {map_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "\n",
    "    # for x, y in train_loader:\n",
    "    #     x = x.to(DEVICE)\n",
    "    #     index += 1\n",
    "    #     for idx in range(8):\n",
    "    #         if index < 2:\n",
    "    #             continue\n",
    "    #         bboxes = cellboxes_to_boxes(model(x), S=7, B=2, C=1)\n",
    "    #         bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
    "    #         plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n",
    "\n",
    "    #     # import sys\n",
    "    #     # sys.exit()\n",
    "\n",
    "    #     if index == 3:\n",
    "    #         break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
