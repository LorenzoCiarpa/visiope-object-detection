{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv0urKZ_l08V",
    "outputId": "688b00d8-cca0-4634-eb04-f360790cc2a0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from hyperparams import hypers\n",
    "from models.yolo import Yolov2Tiny\n",
    "from models.loss import YoloLossMultiBoxes\n",
    "from train import train_fn\n",
    "from dataprocess.dataset import *\n",
    "from dataprocess.dataprocess import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if hypers.DATASET_PATH == \"LOCAL\":\n",
    "    drive_dir=os.path.join(os.getcwd(), \"archive\",\"data\")\n",
    "elif hypers.DATASET_PATH == \"DRIVE\":\n",
    "    drive_dir=os.path.join(os.getcwd(),\"drive\",\"MyDrive\",\"archive\",\"data\")\n",
    "\n",
    "\n",
    "\n",
    "#Dataframe Creation\n",
    "train_labels=os.path.join(drive_dir,\"train_solution_bounding_boxes (1).csv\")\n",
    "train_imgs_dir=os.path.join(drive_dir,\"training_images\")\n",
    "test_imgs_dir=os.path.join(drive_dir,\"testing_images\")\n",
    "labels_dir=os.path.join(drive_dir,\"label\")\n",
    "images_dir=os.path.join(drive_dir,\"image\")\n",
    "\n",
    "imgs_list=list(sorted(os.listdir(train_imgs_dir)))\n",
    "idxs=list(range(len(imgs_list)))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_idx=idxs[:int(0.8*len(idxs))]\n",
    "val_idx=idxs[int(0.8*len(idxs)):]\n",
    "\n",
    "\n",
    "imgs_list=list(sorted(os.listdir(train_imgs_dir)))    \n",
    "\n",
    "\n",
    "\n",
    "model = Yolov2Tiny(split_size=7, num_boxes=hypers.NUM_BOXES, num_classes=hypers.NUM_CLASSES).to(hypers.DEVICE)\n",
    "optimizer = optim.Adam( model.parameters(), lr=hypers.LEARNING_RATE, weight_decay=hypers.WEIGHT_DECAY )\n",
    "loss_fn = YoloLossMultiBoxes(S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])\n",
    "\n",
    "annotations=create_annotations(images_dir) # LIST LIKE: 0     vid_4_1000.jpg   vid_4_1000.txt\n",
    "annotations_predict=create_annotations(test_imgs_dir) # LIST LIKE: 0     vid_4_1000.jpg   vid_4_1000.txt\n",
    "\n",
    "\n",
    "dataset=VOCDataset(annotations, labels_dir, images_dir, S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, transform=transform)\n",
    "dataset_predict=VOCDatasetPredict(annotations_predict, test_imgs_dir, S=7, B=hypers.NUM_BOXES, C=hypers.NUM_CLASSES, transform=transform)\n",
    "\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [300, 55])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=hypers.BATCH_SIZE,\n",
    "                            pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=hypers.BATCH_SIZE,\n",
    "                        pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "predict_loader = DataLoader(dataset=dataset_predict, batch_size=hypers.BATCH_SIZE,\n",
    "                        pin_memory=hypers.PIN_MEMORY, shuffle=True, drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
